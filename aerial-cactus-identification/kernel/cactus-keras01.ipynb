{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sergs\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4d0e1dede477>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvalidation_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtest_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdatagen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#base_dir = '/Users/fchollet/Downloads/cats_and_dogs_small'\n",
    "root_dir = r'C:\\Temp'\n",
    "\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "validation_dir = os.path.join(root_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "# validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "# test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm   # Progress bar\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as T\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "random.seed(6)\n",
    "np.random.seed(6)\n",
    "torch.manual_seed(6)\n",
    "torch.cuda.manual_seed(6)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "root_dir = r'C:\\Temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allDone():\n",
    "    display(Audio(url='../../chicken.mp3', autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_labels = pd.read_csv('../input/train.csv')\n",
    "train_val_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.title('Labels distribution')\n",
    "sns.countplot(train_val_labels['has_cactus']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод сэмплов на экран\n",
    "\n",
    "def show_sample_images(dataloader, batch_size, images_from_batch=0, denormalize=False, classes=None):\n",
    "    if denormalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "    else:\n",
    "        mean = np.array([0., 0., 0.])\n",
    "        std = np.array([1., 1., 1.])\n",
    "    \n",
    "    if images_from_batch == 0 or images_from_batch > batch_size:\n",
    "            images_from_batch = batch_size\n",
    "        \n",
    "    for images, labels in dataloader:\n",
    "        plt.figure(figsize=(20, (batch_size // 20 + 1) * 3))\n",
    "\n",
    "        cols = 12\n",
    "        rows = batch_size // cols + 1\n",
    "        for i in range(images_from_batch):\n",
    "            image = images[i].permute(1, 2, 0).numpy() * std + mean   # Размерность RGB в конец\n",
    "            plt.subplot(rows, cols, i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(image.clip(0, 1))\n",
    "            if classes is not None:\n",
    "                plt.xlabel(classes[labels[i].numpy()])\n",
    "        plt.show()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "# 500 неплохо, попробовать ещё (sched - 25 step)\n",
    "# 250 - 99,48%\n",
    "# 50 - 99,08%\n",
    "\n",
    "train_dir = join(root_dir, 'train')\n",
    "val_dir = join(root_dir, 'val')\n",
    "\n",
    "classes = ['No', 'Cactus']\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "\n",
    "# Протестировали загрузку, узнали размер тензора\n",
    "for images, labels in train_dataloader:\n",
    "    print(images.size())\n",
    "    print(labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample_images(train_dataloader, batch_size, 72, denormalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Batch size: {batch_size}')\n",
    "print(f'Train batches: {len(train_dataloader)}, Train samples: {len(train_dataset)}')\n",
    "print(f'Val batches:   {len(val_dataloader)}, Val samples:    {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train_model and validate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_loss_history = []\n",
    "train_batch_accuracy_history = []\n",
    "\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "def validate(model, loss, optimizer):\n",
    "        \n",
    "    dataloader = val_dataloader\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    sum_loss = 0.\n",
    "    sum_accuracy = 0.\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            preds = model(inputs)\n",
    "            loss_value = loss(preds, labels)\n",
    "            preds_class = preds.argmax(dim=1)\n",
    "\n",
    "        sum_loss += loss_value.item()\n",
    "        sum_accuracy += (preds_class == labels.data).float().mean().cpu().numpy().item()\n",
    "\n",
    "    val_loss = sum_loss / len(dataloader)\n",
    "    val_accuracy = sum_accuracy / len(dataloader)\n",
    "\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_accuracy_history.append(val_accuracy)\n",
    "    \n",
    "    print(f'Validation accuracy {val_accuracy * 100:.2f} %, loss {val_loss:.4f}')\n",
    "#     if val_accuracy >= 0.99:\n",
    "#         allDone()\n",
    "#         input()\n",
    "\n",
    "    model.train()  # Вернули как было\n",
    "\n",
    "\n",
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs-1}: \\n', end='')\n",
    "\n",
    "        dataloader = train_dataloader\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        sum_loss = 0.\n",
    "        sum_accuracy = 0.\n",
    "\n",
    "        # Прогон по батчам\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward and backward\n",
    "            with torch.set_grad_enabled(True):\n",
    "                preds = model(inputs)\n",
    "                loss_value = loss(preds, labels)\n",
    "                preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                # scheduler.step()\n",
    "\n",
    "            batch_loss = loss_value.item()\n",
    "            batch_accuracy = (preds_class == labels.data).float().mean().cpu().numpy().item()\n",
    "\n",
    "            sum_loss += batch_loss\n",
    "            sum_accuracy += batch_accuracy\n",
    "            \n",
    "            train_batch_loss_history.append(batch_loss)\n",
    "            train_batch_accuracy_history.append(batch_accuracy)\n",
    "            #print(f'\\r----- {phase}, batch accuracy {train_batch_accuracy * 100:.2f} %, batch loss {train_batch_loss:.4f}')        \n",
    "            #validate(model, loss, optimizer)\n",
    "            \n",
    "        epoch_loss = sum_loss / len(dataloader)\n",
    "        epoch_acc = sum_accuracy / len(dataloader)\n",
    "\n",
    "        train_loss_history.append(epoch_loss)\n",
    "        train_accuracy_history.append(epoch_acc)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Валидация\n",
    "        print('\\n End epoch: ', end='')\n",
    "        validate(model, loss, optimizer)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model, Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "#model = CactusNet()\n",
    "#model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Disable grad for all conv layers - замораживаем слои ResNet\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Заменяем последний слой на наш (512 входов, 2 выхода) (пересоздаём, поэтому будет разморожен)\n",
    "#model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "#model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss() #weight=torch.FloatTensor([1, 1]).cuda())\n",
    "optimizer = torch.optim.Adam(model.parameters())#, lr=1.0e-3, weight_decay=0.01, amsgrad=True)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40], gamma=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Batch size: {batch_size}\\nBatches: {len(train_dataloader)}\\nAll elements: {len(train_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренировочка\n",
    "epochs = int(np.sqrt(batch_size)) + 20  # Чтобы автоматически выбиралось\n",
    "\n",
    "train_model(model, loss, optimizer, scheduler, num_epochs=epochs)\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "    \n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_batch_loss_history, label='Train Batch Loss')\n",
    "plt.plot(train_batch_accuracy_history, label='Train Batch Accuracy')\n",
    "plt.legend();\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_accuracy_history, label='Train accuracy')\n",
    "plt.plot(val_accuracy_history, label='Val accuracy')\n",
    "plt.legend();\n",
    "    \n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(train_loss_history, label='Train Loss')\n",
    "plt.plot(val_loss_history, label='Val Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing test dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим новую папку и перенесём туда тестовый датасет\n",
    "\n",
    "test_dir = join(root_dir, 'test')\n",
    "\n",
    "#shutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = val_transforms\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(test_dir, test_transforms)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# Протестировали загрузку, узнали размер тензора\n",
    "for images, labels in test_dataloader:\n",
    "    print(images.size())\n",
    "    print(labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample_images(test_dataloader, batch_size, 12, denormalize=True, classes=['Unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "i = 1\n",
    "for images, labels in test_dataloader:\n",
    "    images = images.cuda()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        preds = model(images)\n",
    "    test_predictions.append(T.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n",
    "    print(f'\\r{i}/{len(test_dataloader)}', end='')\n",
    "    i += 1\n",
    "    \n",
    "test_predictions = np.concatenate(test_predictions)  # Соединили предсказания по батчам в единый массив\n",
    "\n",
    "# Округлили до 0 и 1\n",
    "test_predictions = (test_predictions >= 0.5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список файлов из каталога test/unknown. \n",
    "# os.walk возвращает кортеж (каталог, имена подкаталогов, список файлов). Нам нужен список файлов [2]\n",
    "test_files = next(iter(os.walk(join(test_dir, 'unknown'))))[2]\n",
    "\n",
    "print(test_files[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame.from_dict({'id': test_files, 'has_cactus': test_predictions})\n",
    "submission_df.set_index('id', inplace=True)\n",
    "submission_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
